{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# importing library\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.cross_validation import train_test_split # for spliting dataset\nfrom sklearn.feature_extraction.text import CountVectorizer # bow-->1gram and 2 gram\nfrom sklearn.feature_extraction.text import TfidfVectorizer # tf-idf\nfrom gensim.models import Word2Vec  # w2v\nfrom gensim.models import KeyedVectors # to understanding w2v using google pre trained model\nfrom sklearn.metrics import accuracy_score # to check the accuracy of model\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.cross_validation import cross_val_score # k-fold cv",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "e1229d7a0a060fa28d9af279edbb18e392f44ade"
      },
      "cell_type": "markdown",
      "source": ">   # Loading the dataset"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4eb4898dd48098f8467ac0842ccf7031c2605dc8"
      },
      "cell_type": "code",
      "source": "#loading the amazon dataset\ndataset=pd.read_csv(\"../input/amazon-fine-food-reviews/Reviews.csv\")",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b055326cd0060297d256f6fbae459a416e9f1377"
      },
      "cell_type": "code",
      "source": "print(dataset.shape)\ndataset.head()\n",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": "(568454, 10)\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "   Id                        ...                                                                       Text\n0   1                        ...                          I have bought several of the Vitality canned d...\n1   2                        ...                          Product arrived labeled as Jumbo Salted Peanut...\n2   3                        ...                          This is a confection that has been around a fe...\n3   4                        ...                          If you are looking for the secret ingredient i...\n4   5                        ...                          Great taffy at a great price.  There was a wid...\n\n[5 rows x 10 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>ProductId</th>\n      <th>UserId</th>\n      <th>ProfileName</th>\n      <th>HelpfulnessNumerator</th>\n      <th>HelpfulnessDenominator</th>\n      <th>Score</th>\n      <th>Time</th>\n      <th>Summary</th>\n      <th>Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>B001E4KFG0</td>\n      <td>A3SGXH7AUHU8GW</td>\n      <td>delmartian</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n      <td>1303862400</td>\n      <td>Good Quality Dog Food</td>\n      <td>I have bought several of the Vitality canned d...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>B00813GRG4</td>\n      <td>A1D87F6ZCVE5NK</td>\n      <td>dll pa</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1346976000</td>\n      <td>Not as Advertised</td>\n      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>B000LQOCH0</td>\n      <td>ABXLMWJIXXAIN</td>\n      <td>Natalia Corres \"Natalia Corres\"</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1219017600</td>\n      <td>\"Delight\" says it all</td>\n      <td>This is a confection that has been around a fe...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>B000UA0QIQ</td>\n      <td>A395BORC6FGVXV</td>\n      <td>Karl</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1307923200</td>\n      <td>Cough Medicine</td>\n      <td>If you are looking for the secret ingredient i...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>B006K2ZZ7K</td>\n      <td>A1UQRSCLF8GW1T</td>\n      <td>Michael D. Bigham \"M. Wassir\"</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>1350777600</td>\n      <td>Great taffy</td>\n      <td>Great taffy at a great price.  There was a wid...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "f115e029b492a93acade9b6bd568620e86245067"
      },
      "cell_type": "markdown",
      "source": "> # preprocessing the data"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e20017e38dbc2e0162ad8c0e967ef4cbb185f982"
      },
      "cell_type": "code",
      "source": "# sorting the value\ndataset.sort_values(by='Id',inplace=True )\n#finding the dublicate values using 'df.dublicated'\ndataset[dataset.duplicated(subset={'ProfileName','HelpfulnessNumerator','HelpfulnessDenominator','Score','Time'})].shape\n#alternate way to drop dublicate values\ndataset_no_dup=dataset.drop_duplicates(subset={'ProfileName','Score','Time','Summary'},keep='first')\nprint(f\"before {dataset.shape}\")\nprint(f\"after removing duplicate values-->shape = {dataset_no_dup.shape}\")\n# %age of no. of review reamin in data set\n(dataset_no_dup.size/dataset.size)*100\n\n# removing reviews where \"HelpfulnessNumerator>HelpfulnessDenominator\"\ndataset_no_dup=dataset_no_dup[dataset_no_dup['HelpfulnessNumerator']<=dataset_no_dup['HelpfulnessDenominator']]\n",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": "before (568454, 10)\nafter removing duplicate values-->shape = (393141, 10)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8f32067d78d1791819e62ed3d5c2cf627a47718f"
      },
      "cell_type": "code",
      "source": "# taking reviews whose score is not equal to 3\nfiltered_dataset=dataset_no_dup[dataset_no_dup['Score']!=3]\nfiltered_dataset.shape\n#creating a function to filter the reviews (if score>3 --> positive , if score<3 --> negative)\ndef partition(x):\n    if x>3:\n        return 'positive'\n    else:\n        return 'negative'\n\nscore=filtered_dataset['Score']\npos_neg=score.map(partition)\nfiltered_dataset['Score']=pos_neg\nprint(filtered_dataset.shape)\nfiltered_dataset.head()\n\n",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": "(363393, 10)\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  del sys.path[0]\n",
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "   Id                        ...                                                                       Text\n0   1                        ...                          I have bought several of the Vitality canned d...\n1   2                        ...                          Product arrived labeled as Jumbo Salted Peanut...\n2   3                        ...                          This is a confection that has been around a fe...\n3   4                        ...                          If you are looking for the secret ingredient i...\n4   5                        ...                          Great taffy at a great price.  There was a wid...\n\n[5 rows x 10 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>ProductId</th>\n      <th>UserId</th>\n      <th>ProfileName</th>\n      <th>HelpfulnessNumerator</th>\n      <th>HelpfulnessDenominator</th>\n      <th>Score</th>\n      <th>Time</th>\n      <th>Summary</th>\n      <th>Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>B001E4KFG0</td>\n      <td>A3SGXH7AUHU8GW</td>\n      <td>delmartian</td>\n      <td>1</td>\n      <td>1</td>\n      <td>positive</td>\n      <td>1303862400</td>\n      <td>Good Quality Dog Food</td>\n      <td>I have bought several of the Vitality canned d...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>B00813GRG4</td>\n      <td>A1D87F6ZCVE5NK</td>\n      <td>dll pa</td>\n      <td>0</td>\n      <td>0</td>\n      <td>negative</td>\n      <td>1346976000</td>\n      <td>Not as Advertised</td>\n      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>B000LQOCH0</td>\n      <td>ABXLMWJIXXAIN</td>\n      <td>Natalia Corres \"Natalia Corres\"</td>\n      <td>1</td>\n      <td>1</td>\n      <td>positive</td>\n      <td>1219017600</td>\n      <td>\"Delight\" says it all</td>\n      <td>This is a confection that has been around a fe...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>B000UA0QIQ</td>\n      <td>A395BORC6FGVXV</td>\n      <td>Karl</td>\n      <td>3</td>\n      <td>3</td>\n      <td>negative</td>\n      <td>1307923200</td>\n      <td>Cough Medicine</td>\n      <td>If you are looking for the secret ingredient i...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>B006K2ZZ7K</td>\n      <td>A1UQRSCLF8GW1T</td>\n      <td>Michael D. Bigham \"M. Wassir\"</td>\n      <td>0</td>\n      <td>0</td>\n      <td>positive</td>\n      <td>1350777600</td>\n      <td>Great taffy</td>\n      <td>Great taffy at a great price.  There was a wid...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "98f0f5e3ffd97d7a7e6526de7aa4e71919170bbb"
      },
      "cell_type": "code",
      "source": "#changing the format of timestamp to ('%Y-%m-%d %H:%M:%S'\nimport time\nimport datetime\ntime=[]\nfor timestamp in filtered_dataset['Time']:\n    t=datetime.datetime.fromtimestamp(timestamp).strftime(('%Y-%m-%d %H:%M:%S'))\n    time.append(t)\nfiltered_dataset['time']=time   ",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  \n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3649607aa7f860e0c4fbd6250a5db7d258ebef69"
      },
      "cell_type": "code",
      "source": "# sort by time\nfiltered_dataset.sort_values(by='time',inplace=True)",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  \n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4bfc6dd18200a439fe4480be0cfabe6f8486020d"
      },
      "cell_type": "code",
      "source": "import re\nimport nltk\nfrom nltk.corpus import stopwords\n\nsno = nltk.stem.SnowballStemmer('english')#snowball stemmer\n\nstop=set(stopwords.words('english')) #set of stopwords\n\n#clean html tags\ndef cleanhtml(sent):\n    pattern=re.compile(r'<.*?>')\n    cleansent=re.sub(pattern,\" \",sent)\n    return cleansent\n\n#cleean punctuation\ndef cleanpunc(word):\n    clean_punc=re.sub(r'[?|!|\\'|\"|#]',' ',word)\n    clean_punc=re.sub(r'[.|,|)|(|\\|/]',' ',clean_punc)\n    return clean_punc",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c8c1b53bc92bc4ea60aa1bec6083212c077c7420"
      },
      "cell_type": "code",
      "source": "import string\n\nx=0 # number of reviews you want to clean/pre-processed\npositive_words=[]\nnegative_words=[]\nstr1=''\nfinal_sent=[] # storing the list of final pre-processed sentences\ni=0\n\nfor sent in filtered_dataset[\"Text\"]:\n    sent=cleanhtml(sent) #removing html tags\n    filtered_sentence=[]\n    for w in sent.split():\n        for clean_words in cleanpunc(w).split():\n            if((len(clean_words)>2) & (clean_words.isalpha())):\n                if (clean_words.lower() not in stop):\n                    s=(sno.stem(clean_words.lower()))\n                    filtered_sentence.append(s)\n                    if (filtered_dataset['Score'].values[i]=='positive'):\n                        positive_words.append(s)\n                    if (filtered_dataset['Score'].values[i]=='negative'):\n                        negative_words.append(s)\n                else:\n                    continue\n            else:\n                continue\n    str1=\" \".join(filtered_sentence) #str of all the cleaned words\n    final_sent.append(str1) # appending cleaned words to sentence\n    i=i+1\n          ",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "01c437345ee8684a056bfbdb16664663b639a5cf"
      },
      "cell_type": "code",
      "source": "print(len(final_sent))\nprint(\"\\nBefore cleaning :\\n\",filtered_dataset[\"Text\"][10])\nprint(f\"\\nAfter cleaning :\\n {final_sent[10]}\")\n\n",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": "363393\n\nBefore cleaning :\n I don't know if it's the cactus or the tequila or just the unique combination of ingredients, but the flavour of this hot sauce makes it one of a kind!  We picked up a bottle once on a trip we were on and brought it back home with us and were totally blown away!  When we realized that we simply couldn't find it anywhere in our city we were bummed.<br /><br />Now, because of the magic of the internet, we have a case of the sauce and are ecstatic because of it.<br /><br />If you love hot sauce..I mean really love hot sauce, but don't want a sauce that tastelessly burns your throat, grab a bottle of Tequila Picante Gourmet de Inclan.  Just realize that once you taste it, you will never want to use any other sauce.<br /><br />Thank you for the personal, incredible service!\n\nAfter cleaning :\n know cactus tequila uniqu combin ingredi flavour hot sauc make one kind pick bottl trip brought back home total blown away realiz simpli find anywher citi bum magic internet case sauc ecstat love hot sauc mean realli love hot sauc want sauc tasteless burn throat grab bottl tequila picant gourmet inclan realiz tast never want use sauc thank person incred servic\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6c50e0f9ff51327712924638560bf98819297155"
      },
      "cell_type": "code",
      "source": "filtered_dataset['cleaned_text']=final_sent\nprint(filtered_dataset.shape)\nfiltered_dataset.head()",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": "(363393, 11)\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  \"\"\"Entry point for launching an IPython kernel.\n",
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "   Id                        ...                                                               cleaned_text\n0   1                        ...                          bought sever vital can dog food product found ...\n1   2                        ...                          product arriv label jumbo salt peanut peanut a...\n2   3                        ...                          confect around centuri light pillowi citrus ge...\n3   4                        ...                          look secret ingredi robitussin believ found go...\n4   5                        ...                          great taffi great price wide assort yummi taff...\n\n[5 rows x 11 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>ProductId</th>\n      <th>UserId</th>\n      <th>ProfileName</th>\n      <th>HelpfulnessNumerator</th>\n      <th>HelpfulnessDenominator</th>\n      <th>Score</th>\n      <th>Time</th>\n      <th>Summary</th>\n      <th>Text</th>\n      <th>cleaned_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>B001E4KFG0</td>\n      <td>A3SGXH7AUHU8GW</td>\n      <td>delmartian</td>\n      <td>1</td>\n      <td>1</td>\n      <td>positive</td>\n      <td>1303862400</td>\n      <td>Good Quality Dog Food</td>\n      <td>I have bought several of the Vitality canned d...</td>\n      <td>bought sever vital can dog food product found ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>B00813GRG4</td>\n      <td>A1D87F6ZCVE5NK</td>\n      <td>dll pa</td>\n      <td>0</td>\n      <td>0</td>\n      <td>negative</td>\n      <td>1346976000</td>\n      <td>Not as Advertised</td>\n      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n      <td>product arriv label jumbo salt peanut peanut a...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>B000LQOCH0</td>\n      <td>ABXLMWJIXXAIN</td>\n      <td>Natalia Corres \"Natalia Corres\"</td>\n      <td>1</td>\n      <td>1</td>\n      <td>positive</td>\n      <td>1219017600</td>\n      <td>\"Delight\" says it all</td>\n      <td>This is a confection that has been around a fe...</td>\n      <td>confect around centuri light pillowi citrus ge...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>B000UA0QIQ</td>\n      <td>A395BORC6FGVXV</td>\n      <td>Karl</td>\n      <td>3</td>\n      <td>3</td>\n      <td>negative</td>\n      <td>1307923200</td>\n      <td>Cough Medicine</td>\n      <td>If you are looking for the secret ingredient i...</td>\n      <td>look secret ingredi robitussin believ found go...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>B006K2ZZ7K</td>\n      <td>A1UQRSCLF8GW1T</td>\n      <td>Michael D. Bigham \"M. Wassir\"</td>\n      <td>0</td>\n      <td>0</td>\n      <td>positive</td>\n      <td>1350777600</td>\n      <td>Great taffy</td>\n      <td>Great taffy at a great price.  There was a wid...</td>\n      <td>great taffi great price wide assort yummi taff...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "daafb4a4f3218f63d4596644b540980c4961a66e"
      },
      "cell_type": "markdown",
      "source": "## 1. Bag of word"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a05a5efa7ab7ef69c3476586940e1aab8957951c",
        "_kg_hide-input": true,
        "_kg_hide-output": true
      },
      "cell_type": "code",
      "source": "# one gram-BOW from \"sklean.feature_extraction.text.CountVectorizer\"\ncount_vect=CountVectorizer()\nbow_cleaned_text=count_vect.fit_transform(filtered_dataset['cleaned_text'])\n",
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9a2b7dcc0480bf64e0b527da5f71c5f3d97f81c1"
      },
      "cell_type": "code",
      "source": "# two gram_BOW \ncount_vect_gram=CountVectorizer(ngram_range=(1,2))\nbow_cleaned_text_2gram=count_vect_gram.fit_transform(filtered_dataset['cleaned_text'])",
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6a947fcff0f3104889f106613d5f2a0059952208"
      },
      "cell_type": "code",
      "source": "print(\"bow_cleaned_text\",bow_cleaned_text.shape)\nprint(\"bow_cleaned_text_2gram\",bow_cleaned_text_2gram.shape)",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": "bow_cleaned_text (363393, 70047)\nbow_cleaned_text_2gram (363393, 2881737)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "3752812bac362c5bb8a56c09795a95943195635e"
      },
      "cell_type": "markdown",
      "source": "###  PCA visualisation of BOW- 1 gram"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "31073550b86a58db06c4028af8eb54ff18b6a592"
      },
      "cell_type": "code",
      "source": "from sklearn.preprocessing import StandardScaler\nsc=StandardScaler(with_mean=False)\na=sc.fit_transform(bow_cleaned_text[:4000])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "18142b2e6a948939316d1ebbb8c565ddc712e3f5"
      },
      "cell_type": "code",
      "source": "a.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "a8d4fb0f274111807abede6c9000079393dc4dda"
      },
      "cell_type": "code",
      "source": "a=a.todense()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "58ed83fe038c96a60d76adb400243836fc3a3142"
      },
      "cell_type": "code",
      "source": "from sklearn.manifold import TSNE\nmodel = TSNE(n_components=2, random_state=0, perplexity = 30, n_iter = 5000)\n# configuring the parameteres\n# the number of components = 2\n# default perplexity = 30\n# default learning rate = 200\n# default Maximum number of iterations for the optimization = 1000\n\ntsne_data = model.fit_transform(a)\n\n\n# creating a new data frame which help us in ploting the result data\ntsne_data = np.vstack((tsne_data.T, filtered_dataset['Text'][:4000])).T\ntsne_df = pd.DataFrame(data=tsne_data, columns=(\"dim1\", \"dim2\", \"score\"))\n\n# Ploting the result of tsne\nsns.FacetGrid(tsne_df, hue=\"score\", size=6).map(plt.scatter, 'dim1', 'dim2').add_legend()\nplt.title(\"TSNE for Bag of Words\")\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a0538b5637097de47c1fa7c75a67f32872b633d1"
      },
      "cell_type": "code",
      "source": "\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n# Ploting the result of tsne\nsns.FacetGrid(tsne_df, hue=\"score\", height=6).map(plt.scatter, 'dim1', 'dim2').add_legend()\nplt.title(\"TSNE for Bag of Words\")\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "895599c90ea40038d951fadc252b90af84ea22c7"
      },
      "cell_type": "markdown",
      "source": "## 2. TF-IDF"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0209112be7402ec016daf6d1d4ca9c80742b2f7d"
      },
      "cell_type": "code",
      "source": "# tf-idf \"from sklearn.feature_extraction.text.TfidfVectorizer\"\ntf_idf=TfidfVectorizer()\ntf_idf_cleaned_text=tf_idf.fit_transform(filtered_dataset['cleaned_text'])",
      "execution_count": 35,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a52baad81651bb79c8a55b16553dd15bb4223fbe"
      },
      "cell_type": "code",
      "source": "tf_idf_cleaned_text.shape",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 36,
          "data": {
            "text/plain": "(363393, 70047)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b1ea1e4325da85524ea236db7fe389471603dbd6"
      },
      "cell_type": "code",
      "source": "# tf-idf 2-gram --> increasing no. of gram can increase the no. of dimension drastically\ntf_idf_2gram = TfidfVectorizer(ngram_range=(1,2))\ntf_idf_cleaned_text_2gram = tf_idf_2gram.fit_transform(filtered_dataset['cleaned_text'].values)\nprint(\"the type of count vectorizer \",type(tf_idf_cleaned_text_2gram))\nprint(\"the shape of out text TFIDF vectorizer \",tf_idf_cleaned_text_2gram.get_shape())\nprint(\"the number of unique words including both unigrams and bigrams \", tf_idf_cleaned_text_2gram.get_shape()[1])",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": "the type of count vectorizer  <class 'scipy.sparse.csr.csr_matrix'>\nthe shape of out text TFIDF vectorizer  (363393, 2881737)\nthe number of unique words including both unigrams and bigrams  2881737\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f8e6302b0ce67e34896439a6c8b4d2f942e69798"
      },
      "cell_type": "markdown",
      "source": "## 3. avg word2vec"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "745243999b23a07fc0ac01b719cdba3366dfebe3"
      },
      "cell_type": "code",
      "source": "\"\"\"# understanding w2v using goolgle trained model of 300 dimension\n# w2v lib from \"gensim.models import KeyedVectors\"\nfrom gensim.models import KeyedVectors\ngoogle_w2v=KeyedVectors.load_word2vec_format(\"../input/googlenewsvectorsnegative300/GoogleNews-vectors-negative300.bin.gz\",encoding='utf8',binary=True)\n\"\"\"",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c90234ec181dd4152d191b718b1e8a253c033a34"
      },
      "cell_type": "code",
      "source": "\"\"\"google_w2v.distance('woman','queen')\"\"\"",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0acac0932b93cd9ca55bb22356ffa81017462271"
      },
      "cell_type": "code",
      "source": "# converting our text-->vector using w2v with 50-dim\n# more the dimension of each word = better the semantic of word\n# using lib from \"gensim.models.Word2Vec\"\n# to run w2v we need list of list of the words as w2v covert each world into number of dim\n\nlist_of_sent=[]\nfor sent in filtered_dataset['cleaned_text'].values:\n    list_of_sent.append((str(sent)).split())\nw2v_model=Word2Vec(list_of_sent,min_count=5,size=50)\n# vocablary of w2v model of amazon dataset\nvocab=w2v_model.wv.vocab\nlen(vocab)",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "21817"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "7e909e82711f558ec52e3529ca37f2620e86d4b7"
      },
      "cell_type": "code",
      "source": "# understanding w2v on amzon fine food reviews dataset\nw2v_model.similar_by_word('women')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "_uuid": "fbdfcfaff39a6189234848490463a74cfd91b063"
      },
      "cell_type": "code",
      "source": "# w2v representaion of word \"women\" in 50-dim\nw2v_model.wv['women']",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f4208f81461a7a563e316507552d8196bb555611"
      },
      "cell_type": "code",
      "source": "'''\n-->procedure to make avg w2v of each reviews\n    1. find the w2v of each word\n    2. sum-up w2v of each word in a sentence\n    3. divide the total w2v of sentence by total no. of words in the sentence\n'''\n\n# average Word2Vec\n# compute average word2vec for each review.\nsent_vectors = []; # the avg-w2v for each sentence/review is stored in this list\n\nfor sent in list_of_sent[:20000]: # for each review/sentence\n    sent_vec = np.zeros(50) # as word vectors are of zero length\n    cnt_words =0; # num of words with a valid vector in the sentence/review\n    for word in sent: # for each word in a review/sentence\n        if word in vocab:\n            vec = w2v_model.wv[word]\n            sent_vec += vec\n            cnt_words += 1\n    if cnt_words != 0:\n        sent_vec /= cnt_words\n    sent_vectors.append(sent_vec)\n\nprint(len(sent_vectors))\nprint(len(sent_vectors[0]))",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": "20000\n50\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d2d31b65134574de9a68a4a87f8251c6da3d5eb4"
      },
      "cell_type": "code",
      "source": "sent_vectors[0] #avg w2v of first sentences",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 17,
          "data": {
            "text/plain": "array([ 0.01603449,  0.49089715, -0.10807862, -2.10303584,  0.69066381,\n       -1.13479463, -0.86968518,  0.06382391, -0.08572455, -0.68432397,\n        0.8616731 , -0.71690129, -0.88386354,  0.00310096, -0.19346318,\n       -0.49344944,  0.30754587, -0.56316829, -0.0867224 , -1.29980897,\n        0.61145266,  0.77000769,  0.42954946, -0.28112701, -0.48668469,\n        0.3200143 , -0.33681095,  0.27818683,  0.4912024 ,  0.5521246 ,\n       -0.46394361,  0.36881682, -0.73963399,  0.33445731, -0.14917238,\n       -0.32202016, -0.12751943, -0.53720554,  0.16698155, -0.0551241 ,\n        0.50743894, -0.44015141,  1.16529965, -1.06775678, -0.26140797,\n       -0.01735742,  0.49543894, -0.33265766,  1.18862955,  0.36698836])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "c8f3a429fd62ae075d105a0a715216d8b18d5c77"
      },
      "cell_type": "markdown",
      "source": "## avg  TF-IDF W2V "
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d5e4dca6a2507a4b3129978a6f16a9f95bba488d"
      },
      "cell_type": "code",
      "source": "# tfidf words/col names\ntfidf_feat = tf_idf.get_feature_names()",
      "execution_count": 38,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d97b495bba67a735d62d693681079491ce8b343e"
      },
      "cell_type": "code",
      "source": "# TF-IDF weighted Word2Vec\n\n# final_tf_idf is the sparse matrix with row= sentence, col=word and cell_val = tfidf\n\ntfidf_sent_vectors = []; # the tfidf-w2v for each sentence/review is stored in this list\nrow=0;\nfor sent in list_of_sent[:10000]: # for each review/sentence \n    sent_vec = np.zeros(50) # as word vectors are of zero length\n    weight_sum =0; # num of words with a valid vector in the sentence/review\n    for word in sent: # for each word in a review/sentence\n        if word in vocab:\n            vec = w2v_model.wv[word]\n            # obtain the tf_idfidf of a word in a sentence/review\n            tf_idf = tf_idf_cleaned_text[row, tfidf_feat.index(word)]\n            sent_vec += (vec * tf_idf)\n            weight_sum += tf_idf\n    if weight_sum != 0:\n        sent_vec /= weight_sum\n    tfidf_sent_vectors.append(sent_vec)\n    row += 1",
      "execution_count": 41,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "099cb97eb1c6289d7bdd30b00463dc039e49a0a9"
      },
      "cell_type": "code",
      "source": "len(tfidf_sent_vectors)",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 42,
          "data": {
            "text/plain": "10000"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "9954f7f9ce945b04cf49fda8a52d8d2a20edc7ad"
      },
      "cell_type": "markdown",
      "source": "## K-NN on amazon fine food dataset using different hyperparameter"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e1c7952787b312cca68613523d0429aa957a7ddd"
      },
      "cell_type": "code",
      "source": "# function of K-NN with different hyperparamter\ndef kfold_knn_1(X,y):\n\n    x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42)\n\n    # using k-fold to find best k-value in KNN\n    acc=[]\n    for k in range(1,15,2):\n        clf=KNeighborsClassifier(n_neighbors=k , weights='uniform')\n        cv_scores=cross_val_score(clf,x_train,y_train,cv=10,scoring='accuracy')\n        acc.append(cv_scores.mean()*float(100))\n\n    max_acc=acc[acc.index(max(acc))] # maximum accuarcy\n    k=acc.index(max(acc))+1 # best k-value\n    print(\"\\n**************************k-fold knn (n_neighbors=k , weights='uniform') **********************************\")\n    print('**************** using k-fold to find best K-value **********************')\n    print(f'best accuracy is {max_acc} on cv datatset using 10 fold at k-value {k}')\n\n    #using best k-value to find generalistion value\n    clf=KNeighborsClassifier(n_neighbors=k)\n    clf.fit(x_train,y_train)\n    y_pred=clf.predict(x_test)\n    accuracy=accuracy_score(y_test,y_pred)\n    print(f'genearalisation accuracy on best k-value at k = {k} is accuacy = {accuracy}')\n    \n#----------------------------------------------------------------------------------------------------------------------------    \ndef kfold_knn_2(X,y):\n\n    x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42)\n\n    # using k-fold to find best k-value in KNN\n    acc=[]\n    for k in range(1,15,2):\n        clf=KNeighborsClassifier(n_neighbors=k , weights='distance')\n        cv_scores=cross_val_score(clf,x_train,y_train,cv=10,scoring='accuracy')\n        acc.append(cv_scores.mean()*float(100))\n\n    max_acc=acc[acc.index(max(acc))] # maximum accuarcy\n    k=acc.index(max(acc))+1 # best k-value\n    print(\"\\n**************************k-fold knn (clf=KNeighborsClassifier(n_neighbors=k , weights='distance')**********************************\")\n    print('**************** using k-fold to find best K-value **********************')\n    print(f'best accuracy is {max_acc} on cv datatset using 10 fold at k-value {k}')\n\n    #using best k-value to find generalistion value\n    clf=KNeighborsClassifier(n_neighbors=k)\n    clf.fit(x_train,y_train)\n    y_pred=clf.predict(x_test)\n    accuracy=accuracy_score(y_test,y_pred)\n    print(f'genearalisation accuracy on best k-value at k = {k} is accuacy = {accuracy}')\n    \n#----------------------------------------------------------------------------------------------------------------------------    \n\ndef kfold_knn_3(X,y):\n\n    x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42)\n\n    # using k-fold to find best k-value in KNN\n    acc=[]\n    for k in range(1,15,2):\n        clf=KNeighborsClassifier(n_neighbors=k , weights='uniform' , algorithm='brute')\n        cv_scores=cross_val_score(clf,x_train,y_train,cv=10,scoring='accuracy')\n        acc.append(cv_scores.mean()*float(100))\n\n    max_acc=acc[acc.index(max(acc))] # maximum accuarcy\n    k=acc.index(max(acc))+1 # best k-value\n    print(\"\\n**************************k-fold knn (n_neighbors=k , weights='uniform' , algorithm='brute') **********************************\")\n    print('**************** using k-fold to find best K-value **********************')\n    print(f'best accuracy is {max_acc} on cv datatset using 10 fold at k-value {k}')\n\n    #using best k-value to find generalistion value\n    clf=KNeighborsClassifier(n_neighbors=k)\n    clf.fit(x_train,y_train)\n    y_pred=clf.predict(x_test)\n    accuracy=accuracy_score(y_test,y_pred)\n    print(f'genearalisation accuracy on best k-value at k = {k} is accuacy = {accuracy}')\n\n\n#----------------------------------------------------------------------------------------------------------------------------    \n\ndef kfold_knn_4(X,y):\n\n    x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42)\n\n    # using k-fold to find best k-value in KNN\n    acc=[]\n    for k in range(1,15,2):\n        clf=KNeighborsClassifier(n_neighbors=k , weights='distance' , algorithm='brute')\n        cv_scores=cross_val_score(clf,x_train,y_train,cv=10,scoring='accuracy')\n        acc.append(cv_scores.mean()*float(100))\n\n    max_acc=acc[acc.index(max(acc))] # maximum accuarcy\n    k=acc.index(max(acc))+1 # best k-value\n    print(\"\\n**************************k-fold knn (n_neighbors=k , weights='distance' , algorithm='brute') **********************************\")\n    print('**************** using k-fold to find best K-value **********************')\n    print(f'best accuracy is {max_acc} on cv datatset using 10 fold at k-value {k}')\n\n    #using best k-value to find generalistion value\n    clf=KNeighborsClassifier(n_neighbors=k)\n    clf.fit(x_train,y_train)\n    y_pred=clf.predict(x_test)\n    accuracy=accuracy_score(y_test,y_pred)\n    print(f'genearalisation accuracy on best k-value at k = {k} is accuacy = {accuracy}')\n#----------------------------------------------------------------------------------------------------------------------------    \n\ndef kfold_knn_5(X,y):\n\n    x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42)\n\n    # using k-fold to find best k-value in KNN\n    acc=[]\n    for k in range(1,15,2):\n        clf=KNeighborsClassifier(n_neighbors=k , weights='uniform' , algorithm='kd_tree' )\n        cv_scores=cross_val_score(clf,x_train,y_train,cv=10,scoring='accuracy')\n        acc.append(cv_scores.mean()*float(100))\n\n    max_acc=acc[acc.index(max(acc))] # maximum accuarcy\n    k=acc.index(max(acc))+1 # best k-value\n    print(\"\\n**************************k-fold knn (n_neighbors=k , weights='uniform' , algorithm='kd_tree' ) **********************************\")\n    print('**************** using k-fold to find best K-value **********************')\n    print(f'best accuracy is {max_acc} on cv datatset using 10 fold at k-value {k}')\n\n    #using best k-value to find generalistion value\n    clf=KNeighborsClassifier(n_neighbors=k)\n    clf.fit(x_train,y_train)\n    y_pred=clf.predict(x_test)\n    accuracy=accuracy_score(y_test,y_pred)\n    print(f'genearalisation accuracy on best k-value at k = {k} is accuacy = {accuracy}')\n\n#----------------------------------------------------------------------------------------------------------------------------    \n\ndef kfold_knn_6(X,y):\n\n    x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42)\n\n    # using k-fold to find best k-value in KNN\n    acc=[]\n    for k in range(1,15,2):\n        clf=KNeighborsClassifier(n_neighbors=k , weights='distance' , algorithm='kd_tree' )\n        cv_scores=cross_val_score(clf,x_train,y_train,cv=10,scoring='accuracy')\n        acc.append(cv_scores.mean()*float(100))\n\n    max_acc=acc[acc.index(max(acc))] # maximum accuarcy\n    k=acc.index(max(acc))+1 # best k-value\n    print(\"\\n**************************k-fold knn (n_neighbors=k , weights='distance' , algorithm='kd_tree' ) **********************************\")\n    print('**************** using k-fold to find best K-value **********************')\n    print(f'best accuracy is {max_acc} on cv datatset using 10 fold at k-value {k}')\n\n    #using best k-value to find generalistion value\n    clf=KNeighborsClassifier(n_neighbors=k)\n    clf.fit(x_train,y_train)\n    y_pred=clf.predict(x_test)\n    accuracy=accuracy_score(y_test,y_pred)\n    print(f'genearalisation accuracy on best k-value at k = {k} is accuacy = {accuracy}')\n\n\n    ",
      "execution_count": 43,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1e02e3054451cdc214c4deaa965ec3c491725ff9"
      },
      "cell_type": "markdown",
      "source": "> ## Data splitiing for training and checking accuracy on (bow , tf-idf , avg w2v , avg tf-idf w2v)"
    },
    {
      "metadata": {
        "_uuid": "54017319813eea5a6c20704feb0d0c261537b989"
      },
      "cell_type": "markdown",
      "source": "## *  K-NN ON BOW 1-gram\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "87a5b736221a40cc7a4e85768d3e7d0b8a529ff3"
      },
      "cell_type": "code",
      "source": "#shaping datset for 'X' and 'y' for classification model\nX=bow_cleaned_text[:50000]\ny=filtered_dataset['Score'][:50000]\n#calling function of KNN with different parameter\nkfold_knn_1(X,y)\nkfold_knn_2(X,y)\nkfold_knn_3(X,y)\nkfold_knn_4(X,y)\n",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": "\n**************************k-fold knn (n_neighbors=k , weights='uniform') **********************************\n**************** using k-fold to find best K-value **********************\nbest accuracy is 88.78857351113719 on cv datatset using 10 fold at k-value 7\ngenearalisation accuracy on best k-value at k = 7 is accuacy = 0.8841333333333333\n\n**************************k-fold knn (clf=KNeighborsClassifier(n_neighbors=k , weights='distance')**********************************\n**************** using k-fold to find best K-value **********************\nbest accuracy is 88.74857187661812 on cv datatset using 10 fold at k-value 7\ngenearalisation accuracy on best k-value at k = 7 is accuacy = 0.8841333333333333\n\n**************************k-fold knn (n_neighbors=k , weights='uniform' , algorithm='brute') **********************************\n**************** using k-fold to find best K-value **********************\nbest accuracy is 88.78857351113719 on cv datatset using 10 fold at k-value 7\ngenearalisation accuracy on best k-value at k = 7 is accuacy = 0.8841333333333333\n\n**************************k-fold knn (n_neighbors=k , weights='distance' , algorithm='brute') **********************************\n**************** using k-fold to find best K-value **********************\nbest accuracy is 88.74857187661812 on cv datatset using 10 fold at k-value 7\ngenearalisation accuracy on best k-value at k = 7 is accuacy = 0.8841333333333333\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "302dbb3044b916a4cd403279adfe73b7543db07e"
      },
      "cell_type": "code",
      "source": "#shaping datset for 'X' and 'y' for classification model\nx_train=bow_cleaned_text[:40000]\ny_train=filtered_dataset['Score'][:40000]\nx_test=bow_cleaned_text[40000:50000]\ny_test=filtered_dataset['Score'][40000:50000]",
      "execution_count": 46,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e59f92d2eb384460526ca91892af99dd2907dce7"
      },
      "cell_type": "code",
      "source": "    # function of K-NN with different hyperparamter\n    #def kfold_knn_1(X,y):\n\n    #x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42)\n\n    # using k-fold to find best k-value in KNN\n    acc=[]\n    for k in range(1,15,2):\n        clf=KNeighborsClassifier(n_neighbors=k , weights='uniform')\n        cv_scores=cross_val_score(clf,x_train,y_train,cv=10,scoring='accuracy')\n        acc.append(cv_scores.mean()*float(100))\n\n    max_acc=acc[acc.index(max(acc))] # maximum accuarcy\n    k=acc.index(max(acc))+1 # best k-value\n    print(\"\\n**************************k-fold knn (n_neighbors=k , weights='uniform') **********************************\")\n    print('**************** using k-fold to find best K-value **********************')\n    print(f'best accuracy is {max_acc} on cv datatset using 10 fold at k-value {k}')\n\n    #using best k-value to find generalistion value\n    clf=KNeighborsClassifier(n_neighbors=k)\n    clf.fit(x_train,y_train)\n    y_pred=clf.predict(x_test)\n    accuracy=accuracy_score(y_test,y_pred)\n    print(f'genearalisation accuracy on best k-value at k = {k} is accuacy = {accuracy}')\n    ",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": "\n**************************k-fold knn (n_neighbors=k , weights='uniform') **********************************\n**************** using k-fold to find best K-value **********************\nbest accuracy is 88.97500048734379 on cv datatset using 10 fold at k-value 7\ngenearalisation accuracy on best k-value at k = 7 is accuacy = 0.8746\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "fe3ac02a0b9329045179320c33648d3b78a76b07"
      },
      "cell_type": "markdown",
      "source": "## * K-NN on TF-IDF 1-gram\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f22b6c4265b1da7466720fa2911de2164ca4c444"
      },
      "cell_type": "code",
      "source": "X1=tf_idf_cleaned_text[:20000]\ny1=filtered_dataset['Score'][:20000]\n#calling function of KNN with different parameter\nkfold_knn_4(X1,y1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8bbba83f6740a18a4ad0be547ef8f80c0e0f7019"
      },
      "cell_type": "markdown",
      "source": "## * K-NN on avg W2V\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "48db3001ae13248505ad887b9d3b802a92d4ed35"
      },
      "cell_type": "code",
      "source": "X2=sent_vectors[:20000]\ny2=filtered_dataset['Score'][20000]\n#calling function of KNN with different parameter\nkfold_knn_4(X2,y2)\nkfold_knn_5(X2,y2)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0b116a3cf3e61c1001885c9530b3cd2ea3187d09"
      },
      "cell_type": "markdown",
      "source": "## * K-NN on avg TF-IDF W2V"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ac58cc0b8adc41d2a0f73034ee5834ec90817d9e"
      },
      "cell_type": "code",
      "source": "X3=tfidf_sent_vectors[:20000]\ny3=filtered_dataset['Score'][:20000]\n#calling function of KNN with different parameter\nkfold_knn_4(X3,y3)\nkfold_knn_5(X3,y3)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d29fba37359c9174f00253dc93dcf4ff15542a17"
      },
      "cell_type": "markdown",
      "source": "# Time based splliting and apply K-NN"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4656b953a17ce7d6ba4b86ad2e08a4149bb711b6"
      },
      "cell_type": "code",
      "source": "#shaping datset for 'X' and 'y' for classification model\nx_train=bow_cleaned_text[:40000]\ny_train=filtered_dataset['Score'][:40000]\nx_test=bow_cleaned_text[40000:50000]\ny_test=filtered_dataset['Score'][40000:50000]\n\n\n# function of K-NN for time based splitig dataset\ndef kfold_knn_1(x_train,y_train,x_test,y_test):\n\n    \n\n    # using k-fold to find best k-value in KNN\n    acc=[]\n    for k in range(1,15,2):\n        clf=KNeighborsClassifier(n_neighbors=k , weights='uniform')\n        cv_scores=cross_val_score(clf,x_train,y_train,cv=10,scoring='accuracy')\n        acc.append(cv_scores.mean()*float(100))\n\n    max_acc=acc[acc.index(max(acc))] # maximum accuarcy\n    k=acc.index(max(acc))+1 # best k-value\n    print(\"\\n**************************k-fold knn (n_neighbors=k , weights='uniform') **********************************\")\n    print('**************** using k-fold to find best K-value **********************')\n    print(f'best accuracy is {max_acc} on cv datatset using 10 fold at k-value {k}')\n\n    #using best k-value to find generalistion value\n    clf=KNeighborsClassifier(n_neighbors=k)\n    clf.fit(x_train,y_train)\n    y_pred=clf.predict(x_test)\n    accuracy=accuracy_score(y_test,y_pred)\n    print(f'genearalisation accuracy on best k-value at k = {k} is accuacy = {accuracy}')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a23004fcefef13157b5f30651c8e591927e07d85"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "31754c01ba68384385ea05f7d7aaf9d27c6a44ab"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}